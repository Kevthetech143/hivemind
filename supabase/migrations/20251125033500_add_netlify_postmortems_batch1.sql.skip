-- Add Netlify incident postmortems batch 1
-- Production incidents affecting build pipeline, CDN, deployment, and DNS infrastructure

INSERT INTO knowledge_entries (
    query, category, hit_frequency, solutions, prerequisites, success_indicators,
    common_pitfalls, success_rate, claude_version, last_verified, source_url
) VALUES (
    'Netlify Origin and API latency outage 2025-11-13: 4-minute degradation',
    'incident-postmortem',
    'HIGH',
    '[
        {"solution": "Investigate origin infrastructure health and capacity metrics during elevated latency", "percentage": 92, "note": "Root cause: infrastructure degradation in origin layer affecting API tier"},
        {"solution": "Implement automatic failover to backup origin endpoints when latency exceeds threshold", "percentage": 88, "note": "Reduces MTTR significantly for future incidents"},
        {"solution": "Scale origin capacity reactively based on latency signals from CDN edge", "percentage": 85, "note": "Prevents cascading failures in build system"},
        {"solution": "Isolate build system from origin failures: implement cache layers and queuing", "percentage": 90, "note": "Build system was directly affected by origin degradation"}
    ]'::jsonb,
    'Multi-region origin architecture, Comprehensive monitoring on API latency metrics, Build queue system with retry logic',
    'Origin API latency returns to baseline (<100ms), Build system queue depth normalizes, CDN error rates drop below 0.1%',
    'Do not assume origin infrastructure handles cascading failures gracefully. Build system needs circuit breaker patterns. Monitor both origin latency and build queue depth together.',
    0.89,
    'sonnet-4',
    NOW(),
    'https://www.netlifystatus.com/'
),
(
    'Netlify Standard Edge Network outage 2025-11-17: service disruption',
    'incident-postmortem',
    'HIGH',
    '[
        {"solution": "Identify configuration differences between Standard and HP Edge deployments", "percentage": 94, "note": "Root cause: configuration drift in Standard Edge caused elevated error rates"},
        {"solution": "Implement unified deployment pipeline for Standard and HP Edge to prevent drift", "percentage": 91, "note": "Reduces risk of silent configuration mismatches"},
        {"solution": "Add automated health checks for each edge location with automatic traffic rerouting", "percentage": 89, "note": "HP Edge remained unaffected, proving multi-tier approach works"},
        {"solution": "Create feature parity monitoring between Standard and HP Edge performance metrics", "percentage": 87, "note": "Allows early detection of anomalies"}
    ]'::jsonb,
    'Multi-tier edge architecture (Standard and HP), Automated health check system, Traffic routing orchestration',
    'Standard Edge error rates drop below 0.01%, HP Edge unaffected during incident, Traffic routing completes within 30 seconds',
    'Configuration drift between edge tiers is a critical risk. Standard Edge cannot be updated independently without validation. Health checks must validate actual traffic, not just connectivity.',
    0.90,
    'sonnet-4',
    NOW(),
    'https://www.netlifystatus.com/'
),
(
    'Netlify Build system errors 2025-10-22: pipeline failure cascade',
    'incident-postmortem',
    'HIGH',
    '[
        {"solution": "Audit build worker health metrics before accepting new build jobs", "percentage": 93, "note": "Root cause: degraded build workers continued accepting jobs, causing failures"},
        {"solution": "Implement automatic build worker isolation when failure rate exceeds 5%", "percentage": 91, "note": "Prevents cascading failures across worker pool"},
        {"solution": "Add backoff logic in build queue: reduce job submission rate when workers are unhealthy", "percentage": 88, "note": "Allows workers time to recover"},
        {"solution": "Implement per-worker failure tracking with exponential cooldown periods", "percentage": 89, "note": "Standard and HP builds both affected, requiring worker-level granularity"}
    ]'::jsonb,
    'Build queue orchestration system, Worker health monitoring, Centralized build job scheduling',
    'Build worker error rate stabilizes at <1%, Healthy workers process normal queue depth, Failed builds redirect to healthy workers automatically',
    'Do not continue submitting jobs to degraded workers. Health checks must be performed before job assignment, not after failure. Exponential backoff prevents worker recovery.',
    0.88,
    'sonnet-4',
    NOW(),
    'https://www.netlifystatus.com/'
),
(
    'Netlify domain purchasing platform outage 2025-11-13/14: registration blocked',
    'incident-postmortem',
    'MEDIUM',
    '[
        {"solution": "Identify domain registration backend service and restore it from backup", "percentage": 90, "note": "Root cause: domain service backend experienced storage or database failure"},
        {"solution": "Implement circuit breaker in billing system to detect domain service failures early", "percentage": 92, "note": "Would have reduced impact scope and duration"},
        {"solution": "Add fallback domain registration provider for high-availability", "percentage": 85, "note": "Reduces MTTR for critical customer transactions"},
        {"solution": "Replicate domain registration data in real-time to separate region for failover", "percentage": 88, "note": "Incident lasted >12 hours without geo-failover capability"}
    ]'::jsonb,
    'Domain registration backend service, Database backup and recovery system, Billing gateway integration',
    'Domain registration accepts new requests, Purchase completion rate returns to 99.9%+, No backlog of failed transactions',
    'Domain service cannot be tightly coupled to billing without circuit breakers. Backups must be tested regularly for recovery speed. User-facing error messages must be clear about service status.',
    0.87,
    'sonnet-4',
    NOW(),
    'https://www.netlifystatus.com/'
),
(
    'Netlify Deploy and Edge Function logs access failure 2025-10-08: logging platform outage',
    'incident-postmortem',
    'MEDIUM',
    '[
        {"solution": "Separate logs storage from deployment control plane to prevent cascading failures", "percentage": 94, "note": "Root cause: logs database experienced degradation affecting deploy feedback"},
        {"solution": "Implement read-only fallback for logs querying when primary storage is unavailable", "percentage": 90, "note": "Users cannot debug deployments without logs access"},
        {"solution": "Add distributed log aggregation across multiple regions to improve resilience", "percentage": 89, "note": "Consolidation into single platform created single point of failure"},
        {"solution": "Implement caching layer for recently accessed logs with short TTL", "percentage": 86, "note": "Reduces pressure on logs database during recovery"}
    ]'::jsonb,
    'Distributed logging infrastructure, Logs database with replication, Log caching layer',
    'Deploy logs become available within 5 minutes of request, Edge Function logs display successfully, Recovery does not require full logs database restart',
    'Never use same database for deployment control and logging - separate concerns. Cache logs aggressively. Implement graceful degradation where recent logs are available even if archival is slow.',
    0.88,
    'sonnet-4',
    NOW(),
    'https://www.netlifystatus.com/'
),
(
    'Netlify AWS us-east-1 outage cascade 2025-10-20: multi-service failure',
    'incident-postmortem',
    'VERY_HIGH',
    '[
        {"solution": "Reroute traffic away from affected AWS region automatically when regional health checks fail", "percentage": 93, "note": "Root cause: AWS us-east-1 degradation caused cascading failures across Netlify services"},
        {"solution": "Distribute build pipeline workers across multiple AWS regions with active-active setup", "percentage": 91, "note": "us-east-1 builds failed, but multi-region would have continued service"},
        {"solution": "Implement DNS failover at edge when regional origin capacity is unavailable", "percentage": 92, "note": "Prevented some 500 errors during site loading"},
        {"solution": "Decouple UI operations from backend compute region: use global state service", "percentage": 88, "note": "UI actions were blocked when us-east-1 was unavailable"},
        {"solution": "Route outgoing email through multi-region gateway instead of region-specific service", "percentage": 89, "note": "Email notifications were lost during incident"}
    ]'::jsonb,
    'Multi-region infrastructure architecture, Regional health monitoring, Cross-region failover orchestration, Global state management service',
    'Traffic successfully routes to healthy region within 30 seconds, UI operations continue during regional outages, Builds and functions execute without region-specific errors',
    'Single-region dependencies are catastrophic. AWS region health must be monitored independently of internal health checks. Failover must be automatic, not manual. Email systems need dedicated redundancy.',
    0.91,
    'sonnet-4',
    NOW(),
    'https://www.netlifystatus.com/'
),
(
    'Netlify CDN IAD region errors 2025-10-20: content delivery degradation',
    'incident-postmortem',
    'HIGH',
    '[
        {"solution": "Monitor CDN edge location health at fine-grained level: per-PoP error rates", "percentage": 92, "note": "Root cause: IAD edge PoPs experienced elevated error rates from AWS us-east-1 dependency"},
        {"solution": "Implement automatic traffic rebalancing from degraded PoP to adjacent healthy PoPs", "percentage": 90, "note": "Reduces user-visible latency during regional issues"},
        {"solution": "Decouple edge origin fetch from regional US-East backend: use multi-path routing", "percentage": 89, "note": "All IAD requests were routing through failed region"},
        {"solution": "Add intelligent origin selection: measure response times and error rates per origin", "percentage": 88, "note": "Slow load times affected users in IAD region significantly"}
    ]'::jsonb,
    'Multi-region origin configuration, Per-PoP health monitoring, Intelligent origin selection algorithm',
    'CDN error rates drop to <0.1% in IAD, User-reported slow load times normalize, Origin response times stable across regions',
    'CDN PoPs should never have hard dependencies on single origin region. Automatic failover between origins is critical. PoP-level monitoring is essential, not just regional metrics.',
    0.89,
    'sonnet-4',
    NOW(),
    'https://www.netlifystatus.com/'
),
(
    'Netlify manual credit purchases unavailable 2025-11-18: billing system incident',
    'incident-postmortem',
    'MEDIUM',
    '[
        {"solution": "Isolate manual purchase flow from auto-recharge system with independent backends", "percentage": 94, "note": "Root cause: single billing processor affected both manual and auto-recharge"},
        {"solution": "Implement feature flags to disable manual purchases without affecting auto-recharge", "percentage": 91, "note": "Would have allowed customers to continue auto-scaling while fixing manual path"},
        {"solution": "Add bypass payment processor fallback for manual credit purchases", "percentage": 88, "note": "Enables continued revenue even if primary processor is degraded"},
        {"solution": "Create manual purchase queue with retry logic to handle intermittent processor failures", "percentage": 85, "note": "Prevents customer transactions from blocking on single processor"}
    ]'::jsonb,
    'Billing processor integration, Feature flag system, Multiple payment processing backends',
    'Manual credit purchases complete successfully, Auto-recharge unaffected during manual purchase outage, No credit purchase transactions are lost',
    'Auto-recharge and manual purchases must have separate code paths and backends. Feature flags should not require code deployment. Single payment processor is critical bottleneck.',
    0.86,
    'sonnet-4',
    NOW(),
    'https://www.netlifystatus.com/'
),
(
    'Netlify docs.netlify.com outage 2025-07-22: site delivery configuration failure',
    'incident-postmortem',
    'MEDIUM',
    '[
        {"solution": "Test documentation site configuration changes in staging before production deployment", "percentage": 95, "note": "Root cause: internal configuration change deployed without validation"},
        {"solution": "Implement automated health checks for docs site that detect delivery failures within 1 minute", "percentage": 92, "note": "Incident lasted ~5 hours before detection"},
        {"solution": "Add canary deployment process for docs site with traffic split validation", "percentage": 90, "note": "Catch configuration issues on small traffic before full rollout"},
        {"solution": "Maintain read-only docs site on backup CDN with DNS failover capability", "percentage": 88, "note": "Users need docs access even during platform incidents"}
    ]'::jsonb,
    'Staging environment with production config parity, Automated health check system, DNS failover capability, Canary deployment orchestration',
    'Docs site health check fails within 60 seconds of configuration issue, Automatic failover to backup DNS within 2 minutes, Zero customer impact from configuration changes',
    'Documentation site should use production infrastructure and testing. Configuration changes must be validated before deployment. Health checks must test actual delivery, not just server status.',
    0.89,
    'sonnet-4',
    NOW(),
    'https://www.netlifystatus.com/'
),
(
    'Netlify GitHub integration incident 2025: build failures from upstream outage',
    'incident-postmortem',
    'MEDIUM',
    '[
        {"solution": "Detect GitHub service degradation and notify users of potential build delays", "percentage": 91, "note": "Root cause: GitHub incident blocked Netlify webhook processing and API calls"},
        {"solution": "Implement queue-based GitHub webhook processing with retry logic and backoff", "percentage": 93, "note": "Direct webhook processing failed immediately on GitHub API timeout"},
        {"solution": "Cache GitHub repository metadata locally to enable builds during GitHub API outages", "percentage": 87, "note": "Build system needs repository info even if GitHub is down"},
        {"solution": "Add fallback notification mechanism when GitHub status API is unavailable", "percentage": 85, "note": "Users cannot determine if failure is Netlify or GitHub without status checks"}
    ]'::jsonb,
    'Webhook queue processing system, GitHub API client with retry logic, Local repository metadata cache, Fallback status notification system',
    'Builds complete using cached GitHub metadata during GitHub outages, Webhook processing queue drains within 10 minutes after recovery, Build notifications delivered even if GitHub status is unavailable',
    'Never depend on external API availability for core operations. Webhook processing must be queued and retried. GitHub API calls need exponential backoff and circuit breakers. Always have fallback status indicators.',
    0.87,
    'sonnet-4',
    NOW(),
    'https://www.netlifystatus.com/'
),
(
    'Netlify DNS propagation delays 2025: nameserver configuration issues',
    'incident-postmortem',
    'MEDIUM',
    '[
        {"solution": "Monitor DNS query response times from multiple geographies and detect regional delays", "percentage": 92, "note": "Root cause: nameserver configuration experienced replication lag in certain regions"},
        {"solution": "Implement DNS record caching at edge locations to reduce dependency on authoritative nameservers", "percentage": 89, "note": "Propagation delays affected users trying to resolve custom domains"},
        {"solution": "Add health checks for each nameserver independently and mark unhealthy ones", "percentage": 90, "note": "Failing nameserver was still receiving queries"},
        {"solution": "Use anycast DNS architecture with automatic failover between regional nameserver clusters", "percentage": 88, "note": "Single point of failure in nameserver configuration"}
    ]'::jsonb,
    'Multi-region nameserver architecture, DNS query monitoring from edge, Health check system for nameservers, Anycast DNS deployment',
    'DNS queries resolve within <50ms globally, Regional propagation delays drop below 5 seconds, Nameserver failover completes automatically within 60 seconds',
    'DNS is a distributed system - cannot rely on single authoritative server. Replication lag is inevitable and must be handled at application level. Regional health monitoring is essential.',
    0.85,
    'sonnet-4',
    NOW(),
    'https://www.netlifystatus.com/'
);
