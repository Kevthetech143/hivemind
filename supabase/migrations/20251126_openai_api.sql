-- OpenAI API Error Codes Mining - 25 Entries
-- High-quality solutions from Stack Overflow, GitHub Issues, OpenAI Community

INSERT INTO knowledge_entries (
    query, category, hit_frequency, solutions, prerequisites, success_indicators,
    common_pitfalls, success_rate, claude_version, last_verified, source_url
) VALUES
('Error code: 429 - You exceeded your current quota', 'openai', 'HIGH', '[{"solution": "Add payment method to your OpenAI account. Visit Settings → Billing → Add to credit balance, then create a NEW API key after funds are added (3-5 min propagation)", "percentage": 95}, {"solution": "Check if free trial credits expired. Visit Settings → Usage to see if grant shows Expired status. Add paid credit to activate account", "percentage": 88}, {"solution": "Create a fresh API key. Old keys created before payment may not work even after adding funds. Delete old key and generate a new one", "percentage": 85}]'::jsonb, 'You need access to Settings page on platform.openai.com', 'API requests work without 429 error; check Usage page shows credits available', 'Not adding a NEW key after payment (old keys stay restricted). Waiting less than 5 minutes for propagation. Not verifying credits were actually added', 0.93, 'haiku', NOW(), 'https://stackoverflow.com/questions/75041580/openai-api-giving-error-429-too-many-requests'),
('Error code: 429 - Too Many Requests rate limit exceeded', 'openai', 'HIGH', '[{"solution": "Implement exponential backoff retry logic. Start with 1 second delay, double on each retry up to 60 seconds max", "percentage": 92}, {"solution": "Check your account tier in Settings → Limits. Tier 1 accounts (new) have restrictive rate limits. Spend $50+ in API requests to reach Tier 2", "percentage": 85}, {"solution": "Verify organization ID is correct. If using org account, pass organization parameter: client = OpenAI(organization=''<YOUR_ORG_ID>'')", "percentage": 80}]'::jsonb, 'You need to be using OpenAI Python SDK or equivalent with retry support', 'Requests resume successfully after exponential backoff. No more 429 errors on retry', 'Using fixed-delay retry (not exponential). Not checking account tier level. Retrying immediately without delay (thundering herd)', 0.90, 'haiku', NOW(), 'https://community.openai.com/t/429-rate-limit-error-without-reaching-rate-limit/66079'),
('Error code: 429 - Insufficient quota despite payment', 'openai', 'MEDIUM', '[{"solution": "Verify auto-recharge is enabled. Visit Settings → Billing → Auto-recharge and toggle it on, then test API call", "percentage": 88}, {"solution": "Check for negative balance. Even $0.01 overage triggers quota error. Add manual credit to clear negative balance", "percentage": 82}, {"solution": "Wait 30 minutes after creating API key. New keys sometimes need time to activate in OpenAI''s backend", "percentage": 75}]'::jsonb, 'You need an OpenAI account with billing configured', 'API requests succeed without 429 errors. Usage shows positive balance', 'Not checking Usage page balance. Assuming auto-recharge is on without verifying. Retrying immediately without waiting for key propagation', 0.88, 'haiku', NOW(), 'https://community.openai.com/t/error-code-429-you-exceeded-your-current-quota/649547'),
('Error code: 401 - Invalid API key provided', 'openai', 'HIGH', '[{"solution": "Verify API key is correct. Go to Settings → API Keys and copy the full key again. Check for truncation or extra spaces", "percentage": 96}, {"solution": "Generate a new API key. Old keys may expire or become invalid. Delete old key in Settings and create fresh one", "percentage": 92}, {"solution": "Check API key is not exposed in browser. Move key to environment variable. In Next.js, use .env.local file and import ''dotenv/config''", "percentage": 89}]'::jsonb, 'You need access to your OpenAI account Settings page', 'API authentication succeeds; no more 401 errors in logs', 'Copying partial key with truncation. Assuming same key works everywhere (must check for exposure in browser). Storing key in client-side code', 0.95, 'haiku', NOW(), 'https://stackoverflow.com/questions/79406597/openai-api-key-in-docker-image-gives-error-as-openai-authenticationerror-error'),
('AuthenticationError: 401 - Incorrect API key provided sk-proj', 'openai', 'HIGH', '[{"solution": "Copy API key from Settings → API Keys page directly. Do not hardcode or guess format. Key must start with sk-proj- or sk- prefix", "percentage": 97}, {"solution": "Check Docker container has API key in environment. Run ''echo $OPENAI_API_KEY'' inside container to verify it''s set", "percentage": 91}, {"solution": "Ensure .env file uses correct variable name ''OPENAI_API_KEY'' (not APIKEY or KEY). SDK looks for specific variable names", "percentage": 88}]'::jsonb, 'You need access to OpenAI Settings to retrieve valid API key', 'Docker container logs show successful authentication; API calls work', 'Manually constructing API key format. Assuming truncated key still works. Not verifying environment variable is actually loaded in container', 0.94, 'haiku', NOW(), 'https://stackoverflow.com/questions/79406597/openai-api-key-in-docker-image-gives-error-as-openai-authenticationerror-error'),
('Error code: 401 - Unauthorized. Access token is missing, invalid, or expired', 'openai', 'MEDIUM', '[{"solution": "For Azure OpenAI: Verify API key and endpoint URL are both correct. Check Settings in Azure Portal for exact endpoint", "percentage": 93}, {"solution": "Check token expiration. Azure tokens expire. Refresh authentication by regenerating keys in Azure Portal", "percentage": 87}, {"solution": "Verify audience URL matches Azure region. Common error: using https://cognitiveservices.azure.com when Azure requires region-specific endpoint", "percentage": 85}]'::jsonb, 'You are using Azure OpenAI, not openai.com. You have Azure Portal access', 'Azure OpenAI API authentication succeeds. Tokens are valid and not expired', 'Mixing standard OpenAI endpoint with Azure keys. Using wrong audience URL. Not refreshing token after regenerating keys', 0.91, 'haiku', NOW(), 'https://stackoverflow.com/questions/79219275/azure-openai-error-401-unauthorized-access-token-is-missing-invalid-audienc'),
('Error code: 401 - Principal does not have access to API Operation', 'openai', 'MEDIUM', '[{"solution": "In Azure: Assign ''Cognitive Services OpenAI User'' role to service principal. Go to Azure Portal → Resource Access Control (IAM)", "percentage": 94}, {"solution": "Verify service principal has correct role assignment. Use Azure CLI: az role assignment list --assignee <principal-id>", "percentage": 89}, {"solution": "Check resource group permissions. Service principal must have access to both the OpenAI resource AND resource group", "percentage": 85}]'::jsonb, 'You are using Azure OpenAI with service principal authentication. You have Azure admin access', 'API calls authenticate successfully; no more 401 access denied errors', 'Assigning wrong role (try Owner when Cognitive Services OpenAI User needed). Not checking resource group permissions. Missing IAM role assignment entirely', 0.92, 'haiku', NOW(), 'https://stackoverflow.com/questions/78864115/authenticationerror-401-principal-does-not-have-access-to-api-operation-when-u'),
('Error code: 503 - That model is currently overloaded with other requests', 'openai', 'HIGH', '[{"solution": "Implement exponential backoff retry. Wait 1s, then 2s, 4s, 8s up to 60s max. This is a temporary server-side issue, not permanent", "percentage": 94}, {"solution": "Contact OpenAI support at help.openai.com with the error message. Include request ID if available. Server capacity issue may persist", "percentage": 80}, {"solution": "Try alternative model temporarily. If GPT-4 overloaded, switch to GPT-3.5-turbo to verify API connection works", "percentage": 82}]'::jsonb, 'You have network connectivity. OpenAI API is reachable', 'Request succeeds after retry with backoff. Alternative model works as fallback', 'Retrying immediately without delay (causes more 503s). Assuming permanent API failure. Not including request ID when contacting support', 0.91, 'haiku', NOW(), 'https://github.com/transitive-bullshit/chatgpt-api/issues/313'),
('InternalServerError: Error code: 503 - No available channels for model', 'openai', 'LOW', '[{"solution": "Check if using third-party API proxy (OneAPI). 503 with Chinese error message usually means proxy service issue, not OpenAI", "percentage": 88}, {"solution": "Switch to official OpenAI API endpoint. Verify you''re using api.openai.com, not a proxy service", "percentage": 90}, {"solution": "If using OneAPI or similar: Contact your proxy provider support. OpenAI library is working correctly", "percentage": 85}]'::jsonb, 'You must have access to your API configuration and know if using proxy', 'API calls work when using official endpoint. Proxy issue confirmed if still broken', 'Confusing proxy errors with OpenAI errors. Not checking which endpoint your code is hitting. Assuming OpenAI library is broken', 0.87, 'haiku', NOW(), 'https://github.com/openai/openai-python/issues/1185'),
('Error code: 400 - Invalid request body', 'openai', 'HIGH', '[{"solution": "Check all required parameters are provided. messages, model, and max_tokens are required for chat completions", "percentage": 95}, {"solution": "Validate message format. Each message must have ''role'' and ''content'' keys. Role must be ''system'', ''user'', or ''assistant''", "percentage": 93}, {"solution": "Verify no typos in field names. ''messages'' not ''message'', ''max_tokens'' not ''max_token'', ''temperature'' not ''temp''", "percentage": 91}]'::jsonb, 'You are making an API request. You have OpenAI SDK or curl available', 'API request succeeds with 200 response. No more 400 errors in logs', 'Typo in parameter names. Sending incomplete message objects. Not following API docs for correct schema', 0.94, 'haiku', NOW(), 'https://platform.openai.com/docs/guides/error-codes'),
('Error code: 400 - Prompt too long. Exceeds max context length', 'openai', 'HIGH', '[{"solution": "Count total tokens in system prompt + user message + max_tokens. Must be under model limit (GPT-4: 8192, GPT-4-Turbo: 128k)", "percentage": 96}, {"solution": "Reduce max_tokens parameter. If input is long, lower completion length. Formula: available = model_limit - prompt_tokens - max_tokens", "percentage": 94}, {"solution": "Summarize or chunk long documents. Split text into smaller pieces, process separately, combine results", "percentage": 88}]'::jsonb, 'You have access to a token counter tool or OpenAI''s token estimator', 'API accepts request. Long inputs now process without 400 error', 'Not counting tokens correctly (char count ≠ token count). Not accounting for system prompt length. Using incorrect model''s context limit', 0.93, 'haiku', NOW(), 'https://platform.openai.com/docs/guides/error-codes'),
('Error code: 400 - Invalid value for parameter ''temperature''', 'openai', 'MEDIUM', '[{"solution": "Check temperature is between 0 and 2. Temperature must be float: 0.7 works, ''7'' as string fails", "percentage": 96}, {"solution": "Temperature 0 = deterministic (always same output). Temperature 2 = maximum randomness. Default 1.0 is balanced", "percentage": 91}, {"solution": "Remove temperature parameter if not needed. Default value is safe and recommended for most use cases", "percentage": 85}]'::jsonb, 'You are passing temperature parameter in API request', 'API accepts request with valid temperature. No 400 validation error', 'Passing temperature as string instead of float. Using value outside 0-2 range. Confusing temperature with top_p parameter', 0.92, 'haiku', NOW(), 'https://platform.openai.com/docs/guides/error-codes'),
('Error code: 401 - Model GPT-4 is not available for your account', 'openai', 'MEDIUM', '[{"solution": "Check model access in Settings → Limits → Models. Verify GPT-4 shows as ''Allowed''", "percentage": 92}, {"solution": "Request access to GPT-4. Visit https://openai.com/waitlist/gpt-4-api and wait for approval (48 hours to 1 week typical)", "percentage": 88}, {"solution": "Use GPT-3.5-turbo as temporary fallback while waiting for GPT-4 access. It''s production-ready and cheaper", "percentage": 90}]'::jsonb, 'You have an active OpenAI account. You can access Settings page', 'Model access shows ''Allowed'' in Settings. API request with GPT-4 succeeds', 'Assuming GPT-4 access is automatic (requires explicit waitlist approval). Using deprecated gpt-4 instead of gpt-4-turbo. Not checking allowed models list', 0.89, 'haiku', NOW(), 'https://platform.openai.com/docs/guides/error-codes'),
('Error code: 404 - The model ''gpt-4'' does not exist or you do not have access', 'openai', 'MEDIUM', '[{"solution": "Use correct model name. Latest: ''gpt-4-turbo'', ''gpt-4o'', ''gpt-3.5-turbo''. Check https://platform.openai.com/docs/models", "percentage": 95}, {"solution": "Verify you have access to the model in Settings → Limits. Model must show ''Allowed'' status", "percentage": 92}, {"solution": "Check for typos in model name. ''gpt-4'' (old) → use ''gpt-4-turbo'' or ''gpt-4o''. ''gpt3.5-turbo'' (wrong) → ''gpt-3.5-turbo''", "percentage": 93}]'::jsonb, 'You have access to OpenAI Settings and model availability list', 'API request with correct model name succeeds. 404 error gone', 'Using deprecated model names (gpt-4 instead of gpt-4-turbo). Typos in model name. Not checking updated model list on docs', 0.94, 'haiku', NOW(), 'https://platform.openai.com/docs/guides/error-codes'),
('Error code: 429 - Rate limit reached. Too many requests per minute', 'openai', 'MEDIUM', '[{"solution": "Check your rate limit tier in Settings → Limits. Display shows requests/min allowed. Don''t exceed this", "percentage": 91}, {"solution": "Implement request queuing. Use queue library to limit concurrent requests. Space them out by 60/rate_limit milliseconds", "percentage": 89}, {"solution": "Request rate limit increase in Settings → Usage Limits. For high volume, OpenAI increases limits after $50+ spent", "percentage": 85}]'::jsonb, 'You can see your current rate limit tier in account settings', 'Requests spread across time. No more 429 rate limit errors on high volume', 'Sending all requests simultaneously (causes spikes exceeding limit). Not queuing requests. Assuming higher tier limit than actually assigned', 0.88, 'haiku', NOW(), 'https://platform.openai.com/docs/guides/rate-limits'),
('Error: Connection refused - Cannot reach API endpoint', 'openai', 'MEDIUM', '[{"solution": "Verify network connectivity. Run: curl https://api.openai.com. Should return 200, not timeout", "percentage": 93}, {"solution": "Check firewall/proxy settings. Some corporate networks block OpenAI. Use VPN or request firewall exception", "percentage": 85}, {"solution": "Verify correct endpoint: https://api.openai.com (not http, not custom domain). Check for typos in base_url", "percentage": 91}]'::jsonb, 'You have network access and curl/networking tools available', 'curl succeeds to api.openai.com. API requests connect successfully', 'Using HTTP instead of HTTPS. Wrong domain (openai.io vs openai.com). Typo in endpoint URL. Firewall misconfigured', 0.87, 'haiku', NOW(), 'https://platform.openai.com/docs/guides/error-codes'),
('Error code: 400 - This model''s maximum context length is 4096 tokens', 'openai', 'MEDIUM', '[{"solution": "Use GPT-4-Turbo (128k context) or GPT-4o (128k context) instead of older GPT-3.5 or standard GPT-4 (8k context)", "percentage": 92}, {"solution": "Reduce input text. Summarize long documents first, then send summary instead of full text", "percentage": 89}, {"solution": "Check max_tokens parameter. Reduce it if input is long. Reserve tokens for both input AND output combined", "percentage": 90}]'::jsonb, 'You need to switch to a model with larger context or reduce input size', 'API accepts long inputs without context length error. Requests process successfully', 'Using old model with small context (GPT-3.5) when Turbo available. Not accounting for output tokens in context limit. Sending entire documents uncompressed', 0.91, 'haiku', NOW(), 'https://platform.openai.com/docs/guides/error-codes'),
('Error code: 401 - Invalid organization. Unauthorized for organization', 'openai', 'LOW', '[{"solution": "Verify organization ID is correct. Copy from Settings → Organization settings, not from URL", "percentage": 94}, {"solution": "Ensure API key belongs to the organization. Generate key while organization is selected in account dropdown", "percentage": 91}, {"solution": "Check organization has active subscription. Free trial organizations may become inactive. Verify billing status", "percentage": 87}]'::jsonb, 'You are using organization accounts. You have org access and can verify settings', 'API calls with organization parameter authenticate successfully', 'Copying org ID from URL bar (may be wrong). Using personal API key for org account. Assuming free trial org stays active indefinitely', 0.89, 'haiku', NOW(), 'https://platform.openai.com/docs/guides/error-codes'),
('Error code: 500 - Internal Server Error from OpenAI', 'openai', 'LOW', '[{"solution": "500 errors are temporary server issues. Implement exponential backoff retry (1s, 2s, 4s, etc) with max 60s", "percentage": 90}, {"solution": "Contact OpenAI status page: https://status.openai.com to check for service incidents", "percentage": 85}, {"solution": "If error persists for hours, email support@openai.com with full error response and request timestamp", "percentage": 78}]'::jsonb, 'You have network connectivity. You can reach OpenAI status page', 'Retry succeeds. API returns valid 200 response. Error does not persist', 'Retrying immediately without backoff. Not checking OpenAI status page. Assuming permanent API failure', 0.85, 'haiku', NOW(), 'https://platform.openai.com/docs/guides/error-codes'),
('Error: ECONNREFUSED - Local proxy or API wrapper service not responding', 'openai', 'LOW', '[{"solution": "If using local proxy: Start the proxy service. Verify it''s listening on correct port (usually 8000 or 3000)", "percentage": 92}, {"solution": "Check proxy is running: curl http://localhost:8000/health should return 200", "percentage": 89}, {"solution": "Verify proxy points to correct OpenAI endpoint. Check proxy config has correct base_url", "percentage": 86}]'::jsonb, 'You are using a local proxy or wrapper. You have access to proxy server', 'Proxy service responds to health check. API requests through proxy work', 'Proxy service not started. Wrong port in connection string. Proxy pointing to wrong upstream endpoint', 0.88, 'haiku', NOW(), 'https://platform.openai.com/docs/guides/error-codes'),
('Error code: 429 - Tokens per minute limit exceeded for large model', 'openai', 'MEDIUM', '[{"solution": "Check Settings → Limits → ''Tokens per minute'' (TPM) not just requests per minute. GPT-4 has lower TPM than RPM", "percentage": 93}, {"solution": "Lower completion tokens requested. Each request counts tokens. Long outputs consume TPM quota faster than many short requests", "percentage": 91}, {"solution": "Space requests further apart. If limit is 40k TPM, calculate: delay = (total_tokens / 40000) * 60 seconds between requests", "percentage": 87}]'::jsonb, 'You can see TPM limit in Settings → Limits. You can calculate token usage', 'Requests space out correctly. TPM limit not exceeded. No more 429 errors', 'Confusing RPM limit with TPM limit (different units). Not counting tokens in output. Sending all requests at once without spacing', 0.90, 'haiku', NOW(), 'https://platform.openai.com/docs/guides/rate-limits'),
('Error: Cannot deserialize response - HTML 503 received instead of JSON', 'openai', 'LOW', '[{"solution": "OpenAI''s edge returned HTML 503 instead of JSON. Retry with backoff. This is temporary infrastructure issue", "percentage": 89}, {"solution": "Check if using file upload endpoints. Files API is more prone to edge errors. Retry file operations", "percentage": 82}, {"solution": "Update SDK to latest version. Newer OpenAI Python SDK handles HTML error responses gracefully", "percentage": 85}]'::jsonb, 'You are using OpenAI SDK. You can update to latest version', 'Retry succeeds with valid JSON response. SDK deserializes correctly', 'Using old SDK version (before HTML response handling). Not retrying immediately. Assuming JSON parsing failure is permanent', 0.84, 'haiku', NOW(), 'https://github.com/openai-php/client/issues/678'),
('Error code: 429 - Free trial credits expired', 'openai', 'HIGH', '[{"solution": "Free trial credits expire after 3 months. Add paid credit by visiting Settings → Billing → Add to credit balance", "percentage": 94}, {"solution": "After adding payment, create new API key. Old keys created during trial cannot be reused with paid accounts", "percentage": 91}, {"solution": "Verify account converted to paid. Check Settings → Billing shows ''Pay as you go'' (not ''Trial credits'')", "percentage": 90}]'::jsonb, 'You need access to OpenAI account Settings and can add payment method', 'API calls succeed after adding paid credit and creating new key', 'Not creating new API key after trial expires. Adding payment but reusing old trial-era keys. Not verifying account tier changed to paid', 0.92, 'haiku', NOW(), 'https://community.openai.com/t/free-trial-period-expired/'),
('Error code: 400 - Invalid value for parameter ''top_p''', 'openai', 'MEDIUM', '[{"solution": "Check top_p is between 0 and 1 (not 0-2 like temperature). top_p 0.1 = less diverse, top_p 1.0 = full diversity", "percentage": 93}, {"solution": "top_p and temperature should not both be specified. Choose one or omit temperature if using top_p", "percentage": 88}, {"solution": "Default top_p 1.0 is safe. Remove if not adjusting nucleus sampling", "percentage": 85}]'::jsonb, 'You are making chat completion API call with top_p parameter', 'API accepts request with valid top_p. No 400 validation error', 'Using value outside 0-1 range for top_p. Using top_p > 1.0 (confusing with temperature range). Specifying both temperature and top_p simultaneously', 0.91, 'haiku', NOW(), 'https://platform.openai.com/docs/guides/error-codes'),
('Error code: 429 - Billing quota exhausted', 'openai', 'HIGH', '[{"solution": "Set monthly budget limit in Settings → Usage Limits. When reached, new requests blocked until reset date", "percentage": 92}, {"solution": "Increase monthly budget or wait until next month for limit reset. Check Settings → Billing for cycle date", "percentage": 89}, {"solution": "Disable auto-recharge if rate is unexpectedly high. Check API call volume and reduce requests", "percentage": 85}]'::jsonb, 'You have access to OpenAI Settings and Usage Limits', 'Monthly budget limit removed or increased. API requests resume after limit reset or budget change', 'Assuming budget limit doesn''t reset monthly. Not checking monthly reset date. Not monitoring API spending regularly', 0.90, 'haiku', NOW(), 'https://platform.openai.com/docs/guides/rate-limits');
