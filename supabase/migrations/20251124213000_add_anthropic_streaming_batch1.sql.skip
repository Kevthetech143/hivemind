-- Add Anthropic streaming and prompt caching documentation solutions batch 1
-- Source: https://platform.claude.com/docs/en/api/streaming
-- Source: https://platform.claude.com/docs/en/build-with-claude/prompt-caching
-- Source: https://platform.claude.com/docs/en/api/errors
-- Source: https://platform.claude.com/docs/en/api/rate-limits
-- Extracted: 2025-11-24

INSERT INTO knowledge_entries (
    query, category, hit_frequency, solutions, prerequisites, success_indicators,
    common_pitfalls, success_rate, claude_version, last_verified, source_url
) VALUES (
    'Anthropic API error 529: Overloaded error in stream',
    'ai-api',
    'HIGH',
    '[
        {"solution": "Implement exponential backoff retry logic with progressive delay", "percentage": 90, "note": "Official recommended approach for overloaded servers"},
        {"solution": "Check Retry-After header in response for wait time guidance", "percentage": 85, "note": "Header provides exact wait duration"},
        {"solution": "Switch to Batches API for non-urgent requests to reduce load", "percentage": 75, "note": "Better for bulk processing during high usage periods"}
    ]'::jsonb,
    'Valid Anthropic API key, Active API request',
    'Stream resumes with 200 status, No further overloaded_error events',
    'Error can occur mid-stream after 200 response via SSE. Do not assume initial 200 means success. Always handle error events during streaming.',
    0.88,
    'sonnet-4',
    NOW(),
    'https://platform.claude.com/docs/en/api/streaming'
),
(
    'Anthropic API streaming connection interrupted or dropped',
    'ai-api',
    'HIGH',
    '[
        {"solution": "Capture successfully received content before failure and construct new request with partial assistant response to resume", "percentage": 85, "note": "Official recovery strategy for interrupted streams"},
        {"solution": "Resume from most recent text block only - tool use and extended thinking blocks cannot be partially recovered", "percentage": 90, "note": "Critical limitation for recovery"},
        {"solution": "Use SDK built-in features for message accumulation and error handling instead of direct API integration", "percentage": 95, "note": "Recommended approach for production systems"}
    ]'::jsonb,
    'Anthropic SDK installed, Partial stream content captured',
    'Stream successfully resumes from interruption point, Complete response assembled',
    'Cannot resume from middle of tool use or extended thinking blocks. Networks may drop idle connections after 10+ minutes. Implement streaming for long-running requests.',
    0.87,
    'sonnet-4',
    NOW(),
    'https://platform.claude.com/docs/en/api/streaming'
),
(
    'Anthropic API error 429: Rate limit exceeded',
    'ai-api',
    'VERY_HIGH',
    '[
        {"solution": "Wait for duration specified in retry-after header before retrying", "percentage": 95, "note": "retry-after header specifies exact seconds to wait"},
        {"solution": "Ramp up traffic gradually and maintain consistent usage patterns to avoid acceleration limits", "percentage": 90, "note": "Prevents sharp usage spikes triggering additional restrictions"},
        {"solution": "Use prompt caching to reduce input tokens counted toward ITPM limits", "percentage": 85, "note": "Cached tokens dont count on most models - 80% cache hit on 2M ITPM = 10M effective tokens"}
    ]'::jsonb,
    'Valid API key with sufficient permissions, Understanding of rate limit type (RPM, ITPM, OTPM)',
    'Request succeeds with 200 status, No 429 errors in response',
    'Rate limits enforced at sub-minute intervals (60 RPM = 1 req/sec). Retrying before retry-after expires continues to fail. Sharp usage increases trigger acceleration limits.',
    0.93,
    'sonnet-4',
    NOW(),
    'https://platform.claude.com/docs/en/api/rate-limits'
),
(
    'Anthropic API long-running request times out after 10+ minutes',
    'ai-api',
    'MEDIUM',
    '[
        {"solution": "Enable streaming to maintain active connection and prevent network timeout", "percentage": 95, "note": "Official highly encouraged approach for long requests", "command": "Set stream: true in request"},
        {"solution": "Switch to Batches API for non-urgent long-running operations", "percentage": 90, "note": "Designed for reliability with long operations"},
        {"solution": "Implement keep-alive mechanism or connection monitoring for non-streaming requests", "percentage": 70, "note": "Network may drop idle connections after 10+ minutes"}
    ]'::jsonb,
    'Anthropic API key, Request expected to exceed 10 minutes processing time',
    'Request completes successfully, Response received within expected timeframe',
    'Networks drop idle connections on long requests. Streaming or batch APIs highly recommended for 10+ minute operations.',
    0.92,
    'sonnet-4',
    NOW(),
    'https://platform.claude.com/docs/en/api/errors'
),
(
    'Python AttributeError: Beta object has no attribute prompt_caching',
    'ai-api',
    'HIGH',
    '[
        {"solution": "Remove beta prefix - change client.beta.prompt_caching.messages.create() to client.messages.create()", "percentage": 98, "note": "Prompt caching is now GA, no longer requires beta namespace"},
        {"solution": "Update Anthropic SDK to latest version supporting GA prompt caching", "percentage": 95, "command": "pip install --upgrade anthropic"}
    ]'::jsonb,
    'Anthropic Python SDK installed, Code using beta.prompt_caching namespace',
    'Code executes without AttributeError, Caching functionality works',
    'Prompt caching moved from beta to GA. Old beta.prompt_caching namespace no longer exists. Update all references to standard messages.create().',
    0.98,
    'sonnet-4',
    NOW(),
    'https://platform.claude.com/docs/en/build-with-claude/prompt-caching'
),
(
    'TypeScript TypeError: Cannot read properties of undefined reading messages in prompt caching',
    'ai-api',
    'HIGH',
    '[
        {"solution": "Remove beta.promptCaching prefix - change client.beta.promptCaching.messages.create() to client.messages.create()", "percentage": 98, "note": "Prompt caching is GA, beta namespace removed"},
        {"solution": "Update Anthropic TypeScript SDK to latest version", "percentage": 95, "command": "npm install @anthropic-ai/sdk@latest"}
    ]'::jsonb,
    'Anthropic TypeScript SDK installed, Code using beta.promptCaching namespace',
    'Code executes without TypeError, Caching works correctly',
    'Beta namespace for prompt caching removed. Update all client.beta.promptCaching references to client.messages for GA API.',
    0.98,
    'sonnet-4',
    NOW(),
    'https://platform.claude.com/docs/en/build-with-claude/prompt-caching'
),
(
    'Anthropic prompt cache not hitting - cache misses every request',
    'ai-api',
    'VERY_HIGH',
    '[
        {"solution": "Ensure cached sections are identical and marked with cache_control in same locations across calls", "percentage": 95, "note": "Most common cause of cache misses"},
        {"solution": "Verify requests occur within 5-minute cache lifetime window", "percentage": 90, "note": "Unused cached prefixes automatically expire after 5 minutes"},
        {"solution": "Check that tool_choice parameter and presence/absence of images remain consistent across requests", "percentage": 88, "note": "These changes invalidate cache"},
        {"solution": "For prompts with 20+ blocks before cache point, add additional cache breakpoints strategically", "percentage": 85, "note": "System checks up to ~20 blocks before breakpoint"},
        {"solution": "Ensure stable JSON key ordering in tool_use blocks - some languages randomize keys", "percentage": 80, "note": "Languages like Swift and Go randomize JSON key order, breaking caches"}
    ]'::jsonb,
    'Prompt caching enabled with cache_control markers, Minimum token thresholds met (1024+ for most models)',
    'Response headers show cache_read_input_tokens > 0, Cache hit rate increases across requests',
    'Changes to tool_choice, images anywhere in prompt, or tool definitions invalidate cache. Concurrent requests miss cache until first response completes. JSON key order must be stable across calls.',
    0.92,
    'sonnet-4',
    NOW(),
    'https://platform.claude.com/docs/en/build-with-claude/prompt-caching'
),
(
    'Anthropic prompt caching error: prompt too short to cache',
    'ai-api',
    'HIGH',
    '[
        {"solution": "Ensure prompt meets minimum token requirements: 1,024 tokens for Opus/Sonnet, 4,096 for Haiku 4.5, 2,048 for Haiku 3.x", "percentage": 95, "note": "Shorter prompts cannot be cached even with cache_control"},
        {"solution": "Combine multiple small prompts or add context to reach minimum threshold", "percentage": 85, "note": "Aggregate content to meet token minimums"},
        {"solution": "Remove cache_control markers from prompts below threshold to avoid errors", "percentage": 90, "note": "Cache control ignored on short prompts"}
    ]'::jsonb,
    'Understanding of model-specific token minimums, Ability to measure prompt token count',
    'Cache successfully activates, Response shows cache_creation_input_tokens > 0',
    'Different models have different minimums. Haiku 4.5 requires 4,096 tokens vs 1,024 for Sonnet/Opus. Empty text blocks cannot be cached.',
    0.96,
    'sonnet-4',
    NOW(),
    'https://platform.claude.com/docs/en/build-with-claude/prompt-caching'
),
(
    'Anthropic Batches API cache hits unreliable or inconsistent',
    'ai-api',
    'MEDIUM',
    '[
        {"solution": "Use 1-hour cache TTL instead of default 5-minute TTL for batch requests", "percentage": 85, "note": "Improves hit rates with concurrent non-sequential processing", "command": "Set longer TTL in cache_control"},
        {"solution": "Accept cache hits are best-effort with Batches API due to concurrent processing", "percentage": 90, "note": "Expected behavior - not all batch requests will hit cache"},
        {"solution": "Pre-warm cache with initial synchronous request before submitting batch", "percentage": 80, "note": "Ensures cache entry exists before batch processing begins"}
    ]'::jsonb,
    'Batches API enabled, Prompt caching configured with cache_control markers',
    'Some batch requests show cache hits, Overall processing cost reduced',
    'Cache hits with Batches API are best-effort due to concurrent and non-sequential processing. Not a bug - expected limitation.',
    0.82,
    'sonnet-4',
    NOW(),
    'https://platform.claude.com/docs/en/build-with-claude/prompt-caching'
),
(
    'Anthropic API error 400: invalid_request_error format or content issue',
    'ai-api',
    'VERY_HIGH',
    '[
        {"solution": "Validate request JSON structure matches API specification exactly", "percentage": 90, "note": "Check for malformed JSON, missing required fields, incorrect types"},
        {"solution": "Verify all required parameters are present (model, messages, max_tokens)", "percentage": 95, "note": "Missing required fields cause 400 errors"},
        {"solution": "Check parameter values are within valid ranges (e.g., max_tokens, temperature)", "percentage": 88, "note": "Out-of-range values rejected as invalid"},
        {"solution": "Use SDK validation helpers instead of manual JSON construction", "percentage": 92, "note": "SDKs catch format errors before sending request"}
    ]'::jsonb,
    'Valid API key, Understanding of API request format',
    'Request returns 200 status, No invalid_request_error in response',
    'Error message usually indicates specific format issue. Common causes: malformed JSON, wrong parameter types, missing required fields, values outside valid ranges.',
    0.93,
    'sonnet-4',
    NOW(),
    'https://platform.claude.com/docs/en/api/errors'
),
(
    'Anthropic API error 401: authentication_error issue with API key',
    'ai-api',
    'VERY_HIGH',
    '[
        {"solution": "Verify API key is correct and not expired or revoked", "percentage": 95, "note": "Check Console for key status"},
        {"solution": "Ensure API key is properly formatted in Authorization header as x-api-key: your-key", "percentage": 92, "note": "Incorrect header format causes auth failure"},
        {"solution": "Check for whitespace or newlines accidentally included in key string", "percentage": 88, "note": "Common copy-paste error"},
        {"solution": "Regenerate API key in Console if key may be compromised", "percentage": 85, "command": "Create new key at console.anthropic.com"}
    ]'::jsonb,
    'Access to Anthropic Console, Ability to view/regenerate API keys',
    'Request succeeds with 200 status, API key authentication works',
    'Keys can be revoked or expired. Always use x-api-key header, not Bearer token format. Whitespace in key string causes silent failure.',
    0.94,
    'sonnet-4',
    NOW(),
    'https://platform.claude.com/docs/en/api/errors'
),
(
    'Anthropic API error 413: request_too_large exceeds 32 MB limit',
    'ai-api',
    'HIGH',
    '[
        {"solution": "Reduce payload size by compressing images, removing unnecessary context, or splitting into multiple requests", "percentage": 90, "note": "Standard limit is 32 MB, some tiers have higher limits"},
        {"solution": "Use image compression before sending - reduce resolution or quality for large images", "percentage": 88, "note": "Images often primary contributor to large payloads"},
        {"solution": "Paginate large context by splitting into multiple sequential requests with conversation history", "percentage": 85, "note": "Maintain context across smaller requests"},
        {"solution": "Check if your tier has higher limits and optimize accordingly", "percentage": 80, "note": "Enterprise tiers may have different limits"}
    ]'::jsonb,
    'Understanding of payload composition, Tools to measure/compress content',
    'Request succeeds with 200 status, Payload under size limit',
    'Limit includes all request data: messages, system prompts, images, tools. Images are major contributor. Base64 encoding increases size ~33%.',
    0.89,
    'sonnet-4',
    NOW(),
    'https://platform.claude.com/docs/en/api/errors'
);
